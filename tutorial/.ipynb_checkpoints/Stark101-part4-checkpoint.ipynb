{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright 2019 StarkWare Industries Ltd.<br> Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. You may obtain a copy of the License at https://www.starkware.co/open-source-license/ <br> Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Query Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Video Lecture (youtube)](https://www.youtube.com/watch?v=CxP28qM4tAc)\n",
    "- [Slides (PDF)](https://starkware.co/wp-content/uploads/2021/12/STARK101-Part4.pdf)\n",
    "\n",
    "### Load the Previous Session\n",
    "Run the next cell to load the variables we'll use in this part. Since it repeats everything done in previous parts - it will take a while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "from channel import Channel\n",
    "from tutorial_sessions import part1, part3 \n",
    "\n",
    "_, _, _, _, _, _, _, f_eval, f_merkle, _ = part1()\n",
    "fri_polys, fri_domains, fri_layers, fri_merkles, _ = part3()\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decommit on a Query\n",
    "\n",
    "Our goal in this part is to generate all the information needed for verifying the commitments of the three previous parts. In this part we write two functions:\n",
    "1. `decommit_on_fri_layers` - sends over the channel data showing that each FRI layer is consistent with the others, when sampled at a specified index.\n",
    "2. `decommit_on_query` - sends data required for decommiting on the trace and then calls `decommit_on_fri_layers`.  <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decommit on the FRI Layers\n",
    "Implement `decommit_on_fri_layers` function. The function gets an index and a channel, and sends over the channel the relevant data for verifying the correctness of the FRI layers. More specifically, it iterates over `fri_layers` and `fri_merkles` and in each iteration it sends the following data (in the stated order):\n",
    "1. The element of the FRI layer at the given index (using `fri_layers`).\n",
    "2. Its authentication path (using the corresponding Merkle tree from `fri_merkles`).\n",
    "3. The element's FRI sibling (i.e., if the element is $cp_i(x)$, then its sibling is $cp_i(-x)$, where $cp_i$ is the current layer's polynomial, and $x$ is an element from the current layer's domain). \n",
    "4. The authentication path of the element's sibling (using the same merkle tree).\n",
    "\n",
    "To get an authentication path of an element, use `get_authentication_path()` of the `MerkleTree` class, with the corresponding index each time. Note that the index of the element's sibling equals to (idx + $\\frac k  2$) mod $k$,  where $k$ is the length of the relevant FRI layer.<br>\n",
    "Note that we do **not** send the authentication path for the element in the last layer. In the last layer, all the elements are equal, regardless of the query, as they are evaluations of a constant polynomial.\n",
    "\n",
    "*(Remember to convert non-string variables into string before sending over the channel.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fix this.\n",
    "def decommit_on_fri_layers(idx, channel):\n",
    "    for layer, merkle in zip(fri_layers[:-1], fri_merkles[:-1]):\n",
    "        # Fix this: send elements and authentication pathes of all the FRI layers but the last one.\n",
    "        idx = idx % len(layer)\n",
    "        k = idx + (len(layer) // 2)\n",
    "        sibling_idx = int(k % len(layer))\n",
    "        # print(\"idx \", idx)\n",
    "        # print(\"sibling_idx \", sibling_idx)\n",
    "        channel.send(str(layer[idx]))\n",
    "        channel.send(str(merkle.get_authentication_path(idx)))\n",
    "        channel.send(str(layer[sibling_idx]))\n",
    "        channel.send(str(merkle.get_authentication_path(sibling_idx)))\n",
    "    # Send the element in the last FRI layer.\n",
    "    channel.send(str(fri_layers[-1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decommit_on_fri_layers(idx, channel):\n",
    "    for layer, merkle in zip(fri_layers[:-1], fri_merkles[:-1]):\n",
    "        length = len(layer)\n",
    "        idx = idx % length\n",
    "        sib_idx = (idx + length // 2) % length        \n",
    "        channel.send(str(layer[idx]))\n",
    "        channel.send(str(merkle.get_authentication_path(idx)))\n",
    "        channel.send(str(layer[sib_idx]))\n",
    "        channel.send(str(merkle.get_authentication_path(sib_idx)))       \n",
    "    channel.send(str(fri_layers[-1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx  7527\n",
      "sibling_idx  3431\n",
      "idx  3431\n",
      "sibling_idx  1383\n",
      "idx  1383\n",
      "sibling_idx  359\n",
      "idx  359\n",
      "sibling_idx  871\n",
      "idx  359\n",
      "sibling_idx  103\n",
      "idx  103\n",
      "sibling_idx  231\n",
      "idx  103\n",
      "sibling_idx  39\n",
      "idx  39\n",
      "sibling_idx  7\n",
      "idx  7\n",
      "sibling_idx  23\n",
      "idx  7\n",
      "sibling_idx  15\n",
      "idx  8168\n",
      "sibling_idx  4072\n",
      "idx  4072\n",
      "sibling_idx  2024\n",
      "idx  2024\n",
      "sibling_idx  1000\n",
      "idx  1000\n",
      "sibling_idx  488\n",
      "idx  488\n",
      "sibling_idx  232\n",
      "idx  232\n",
      "sibling_idx  104\n",
      "idx  104\n",
      "sibling_idx  40\n",
      "idx  40\n",
      "sibling_idx  8\n",
      "idx  8\n",
      "sibling_idx  24\n",
      "idx  8\n",
      "sibling_idx  0\n",
      "idx  1190\n",
      "sibling_idx  5286\n",
      "idx  1190\n",
      "sibling_idx  3238\n",
      "idx  1190\n",
      "sibling_idx  166\n",
      "idx  166\n",
      "sibling_idx  678\n",
      "idx  166\n",
      "sibling_idx  422\n",
      "idx  166\n",
      "sibling_idx  38\n",
      "idx  38\n",
      "sibling_idx  102\n",
      "idx  38\n",
      "sibling_idx  6\n",
      "idx  6\n",
      "sibling_idx  22\n",
      "idx  6\n",
      "sibling_idx  14\n",
      "idx  2668\n",
      "sibling_idx  6764\n",
      "idx  2668\n",
      "sibling_idx  620\n",
      "idx  620\n",
      "sibling_idx  1644\n",
      "idx  620\n",
      "sibling_idx  108\n",
      "idx  108\n",
      "sibling_idx  364\n",
      "idx  108\n",
      "sibling_idx  236\n",
      "idx  108\n",
      "sibling_idx  44\n",
      "idx  44\n",
      "sibling_idx  12\n",
      "idx  12\n",
      "sibling_idx  28\n",
      "idx  12\n",
      "sibling_idx  4\n",
      "idx  1262\n",
      "sibling_idx  5358\n",
      "idx  1262\n",
      "sibling_idx  3310\n",
      "idx  1262\n",
      "sibling_idx  238\n",
      "idx  238\n",
      "sibling_idx  750\n",
      "idx  238\n",
      "sibling_idx  494\n",
      "idx  238\n",
      "sibling_idx  110\n",
      "idx  110\n",
      "sibling_idx  46\n",
      "idx  46\n",
      "sibling_idx  14\n",
      "idx  14\n",
      "sibling_idx  30\n",
      "idx  14\n",
      "sibling_idx  6\n",
      "idx  1889\n",
      "sibling_idx  5985\n",
      "idx  1889\n",
      "sibling_idx  3937\n",
      "idx  1889\n",
      "sibling_idx  865\n",
      "idx  865\n",
      "sibling_idx  353\n",
      "idx  353\n",
      "sibling_idx  97\n",
      "idx  97\n",
      "sibling_idx  225\n",
      "idx  97\n",
      "sibling_idx  33\n",
      "idx  33\n",
      "sibling_idx  1\n",
      "idx  1\n",
      "sibling_idx  17\n",
      "idx  1\n",
      "sibling_idx  9\n",
      "idx  3828\n",
      "sibling_idx  7924\n",
      "idx  3828\n",
      "sibling_idx  1780\n",
      "idx  1780\n",
      "sibling_idx  756\n",
      "idx  756\n",
      "sibling_idx  244\n",
      "idx  244\n",
      "sibling_idx  500\n",
      "idx  244\n",
      "sibling_idx  116\n",
      "idx  116\n",
      "sibling_idx  52\n",
      "idx  52\n",
      "sibling_idx  20\n",
      "idx  20\n",
      "sibling_idx  4\n",
      "idx  4\n",
      "sibling_idx  12\n",
      "idx  5798\n",
      "sibling_idx  1702\n",
      "idx  1702\n",
      "sibling_idx  3750\n",
      "idx  1702\n",
      "sibling_idx  678\n",
      "idx  678\n",
      "sibling_idx  166\n",
      "idx  166\n",
      "sibling_idx  422\n",
      "idx  166\n",
      "sibling_idx  38\n",
      "idx  38\n",
      "sibling_idx  102\n",
      "idx  38\n",
      "sibling_idx  6\n",
      "idx  6\n",
      "sibling_idx  22\n",
      "idx  6\n",
      "sibling_idx  14\n",
      "idx  396\n",
      "sibling_idx  4492\n",
      "idx  396\n",
      "sibling_idx  2444\n",
      "idx  396\n",
      "sibling_idx  1420\n",
      "idx  396\n",
      "sibling_idx  908\n",
      "idx  396\n",
      "sibling_idx  140\n",
      "idx  140\n",
      "sibling_idx  12\n",
      "idx  12\n",
      "sibling_idx  76\n",
      "idx  12\n",
      "sibling_idx  44\n",
      "idx  12\n",
      "sibling_idx  28\n",
      "idx  12\n",
      "sibling_idx  4\n",
      "idx  2518\n",
      "sibling_idx  6614\n",
      "idx  2518\n",
      "sibling_idx  470\n",
      "idx  470\n",
      "sibling_idx  1494\n",
      "idx  470\n",
      "sibling_idx  982\n",
      "idx  470\n",
      "sibling_idx  214\n",
      "idx  214\n",
      "sibling_idx  86\n",
      "idx  86\n",
      "sibling_idx  22\n",
      "idx  22\n",
      "sibling_idx  54\n",
      "idx  22\n",
      "sibling_idx  6\n",
      "idx  6\n",
      "sibling_idx  14\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# Test against a precomputed hash.\n",
    "test_channel = Channel()\n",
    "for query in [7527, 8168, 1190, 2668, 1262, 1889, 3828, 5798, 396, 2518]:\n",
    "    decommit_on_fri_layers(query, test_channel)\n",
    "assert test_channel.state == 'ad4fe9aaee0fbbad0130ae0fda896393b879c5078bf57d6c705ec41ce240861b', 'State of channel is wrong.'\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decommit on the Trace Polynomial\n",
    "To prove that indeed the FRI layers we decommit on were generated from evaluation of the composition polynomial, we must also send:\n",
    "1. The value $f(x)$ with its authentication path.\n",
    "2. The value $f(gx)$ with its authentication path.\n",
    "3. The value $f(g^2x)$ with its authentication path. <br>\n",
    "The verifier, knowing the random coefficients of the composition polynomial, can compute its evaluation at $x$, and compare it with the first element sent from the first FRI layer.\n",
    "\n",
    "The function `decommit_on_query` should therefore send the above (1, 2, and 3) over the channel, and then call `decommit_on_fri_layers`. <br> <br>\n",
    "\n",
    "Importantly, even though $x, gx, g^2x$ are consecutive elements (modulo the group size $|G|$) in the trace, the evaluations of `f_eval` in these points are actually 8 elements apart. The reason for this is that we \"blew up\" the trace to 8 times its size in part I, to obtain a Reed Solomon codeword.\n",
    "\n",
    "*Reminder: `f_eval` is the evaluation of the composition polynomial, and `f_merkle` is the corresponding Merkle tree.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decommit_on_query(idx, channel):\n",
    "    # Send elements and authentication pathes for f(x), f(gx) and f(g^2x) over the channel. \n",
    "    channel.send(str(f_eval[idx]))\n",
    "    channel.send(str(f_merkle.get_authentication_path(idx)))\n",
    "    # print(f_eval[idx])\n",
    "    \n",
    "    channel.send(str(f_eval[idx + 8]))\n",
    "    channel.send(str(f_merkle.get_authentication_path(idx + 8)))\n",
    "    # print(f_eval[idx + 8])\n",
    "    \n",
    "    channel.send(str(f_eval[idx + 8 * 2]))\n",
    "    channel.send(str(f_merkle.get_authentication_path(idx + 8 * 2)))\n",
    "    # print(f_eval[idx + 8 * 2])\n",
    "    \n",
    "    decommit_on_fri_layers(idx, channel) # No need to fix this line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decommit_on_query(idx, channel): \n",
    "    assert idx + 16 < len(f_eval), f'query index: {idx} is out of range. Length of layer: {len(f_eval)}.'\n",
    "    channel.send(str(f_eval[idx])) # f(x).\n",
    "    channel.send(str(f_merkle.get_authentication_path(idx))) # auth path for f(x).\n",
    "    channel.send(str(f_eval[idx + 8])) # f(gx).\n",
    "    channel.send(str(f_merkle.get_authentication_path(idx + 8))) # auth path for f(gx).\n",
    "    channel.send(str(f_eval[idx + 16])) # f(g^2x).\n",
    "    channel.send(str(f_merkle.get_authentication_path(idx + 16))) # auth path for f(g^2x).\n",
    "    decommit_on_fri_layers(idx, channel)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# Test against a precomputed hash.\n",
    "test_channel = Channel()\n",
    "for query in [8134, 1110, 1134, 6106, 7149, 4796, 144, 4738, 957]:\n",
    "    decommit_on_query(query, test_channel)\n",
    "assert test_channel.state == '16a72acce8d10ffb318f8f5cd557930e38cdba236a40439c9cf04aaf650cfb96', 'State of channel is wrong.'\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decommit on a Set of Queries\n",
    "To finish the proof, the prover gets a set of random queries from the channel, i.e., indices between 0 to 8191, and decommits on each query.\n",
    "\n",
    "Use the function that you just implemented `decommit_on_query()`, and `Channel.receive_random_int` to generate 3 random queries and decommit on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fix this.\n",
    "def decommit_fri(channel):\n",
    "    for query in range(3):\n",
    "        # why -16 :/\n",
    "        decommit_on_query(channel.receive_random_int(0, 8191 - 16), channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decommit_fri(channel):\n",
    "    for query in range(3):\n",
    "        # Get a random index from the verifier and send the corresponding decommitment.\n",
    "        decommit_on_query(channel.receive_random_int(0, 8191-16), channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "State of channel is wrong.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m test_channel \u001b[38;5;241m=\u001b[39m Channel()\n\u001b[1;32m      2\u001b[0m decommit_fri(test_channel)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m test_channel\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meb96b3b77fe6cd48cfb388467c72440bdf035c51d0cfe8b4c003dd1e65e952fd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState of channel is wrong.\u001b[39m\u001b[38;5;124m'\u001b[39m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSuccess!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: State of channel is wrong."
     ]
    }
   ],
   "source": [
    "test_channel = Channel()\n",
    "decommit_fri(test_channel)\n",
    "assert test_channel.state == 'eb96b3b77fe6cd48cfb388467c72440bdf035c51d0cfe8b4c003dd1e65e952fd', 'State of channel is wrong.' \n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proving Time!\n",
    "Run the following cell that ties it all together, running all previous code, as well as the functions you wrote in this part, and prints the proof."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tutorial_sessions import part1, part3 \n",
    "\n",
    "start = time.time()\n",
    "start_all = start\n",
    "print(\"Generating the trace...\")\n",
    "_, _, _, _, _, _, _, f_eval, f_merkle, _ = part1()\n",
    "print(f'{time.time() - start}s')\n",
    "start = time.time()\n",
    "print(\"Generating the composition polynomial and the FRI layers...\")\n",
    "fri_polys, fri_domains, fri_layers, fri_merkles, channel = part3()\n",
    "print(f'{time.time() - start}s')\n",
    "start = time.time()\n",
    "print(\"Generating queries and decommitments...\")\n",
    "decommit_fri(channel)\n",
    "print(f'{time.time() - start}s')\n",
    "start = time.time()\n",
    "print(channel.proof)\n",
    "print(f'Overall time: {time.time() - start_all}s')\n",
    "print(f'Uncompressed proof length in characters: {len(str(channel.proof))}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
